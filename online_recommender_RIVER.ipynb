{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1197e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# NOTEBOOK: Online Factorization Machine with River\n",
    "########################################\n",
    "\n",
    "# %% [markdown]\n",
    "# # 0. Setup & Data Loading\n",
    "# \n",
    "# This notebook assumes you've already produced a `final_df` DataFrame with the columns:\n",
    "# - `ClientID`, `ProductID`\n",
    "# - `SalesNetAmountEuro`, `Quantity_sold`\n",
    "# - Time-based columns: `TransactionDate`, `Month`, `DayOfWeek`, `Season`, etc.\n",
    "# - Demographics: `ClientGender`, `Age`, `ClientSegment`, `ClientCountry`, ...\n",
    "# - Product attributes: `Category`, `FamilyLevel1`, `FamilyLevel2`, `Brand`, `Universe`, ...\n",
    "# - Past features (e.g. `CumulativeSpent`, `MostBoughtBrandSoFar`, etc.)\n",
    "# - RFM windows: `Frequency_30`, `Monetary_30`, `Recency_30`, etc. (optional if you want them as features)\n",
    "# \n",
    "# We'll simulate online training in chronological order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# For the recommendation model\n",
    "from river import compose\n",
    "from river import reco\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 0.1 Load the Preprocessed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda87387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Load final_df from parquet (or CSV, if you prefer)\n",
    "final_df = pd.read_parquet(\"final_df.parquet\")\n",
    "\n",
    "# Verify the structure\n",
    "print(\"Shape:\", final_df.shape)\n",
    "display(final_df.head())\n",
    "display(final_df.dtypes)\n",
    "\n",
    "# Sort by time so we can simulate incremental learning in chronological order\n",
    "final_df = final_df.sort_values(\"TransactionDate\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07415f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # 1. Feature Preparation for River\n",
    "# \n",
    "# River’s **Factorization Machine** (`FMRecommender`) or `BiasedMF` expects:\n",
    "# - A **user ID** feature\n",
    "# - An **item ID** feature\n",
    "# - (Optionally) additional side features\n",
    "# - A **target** (for implicit, often 1 for a purchase, 0 for a negative sample)\n",
    "# \n",
    "# We will:\n",
    "# 1. Identify the user column (`ClientID`) and the item column (`ProductID`).\n",
    "# 2. Prepare any extra features as a dictionary per row (e.g. `{\"Age\": 35, \"Brand\": \"Nike\"}`).\n",
    "# 3. Decide how to handle **negative sampling**, because we only have positives (purchases).\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1.1 Basic negative sampling function\n",
    "# \n",
    "# In implicit feedback scenarios, we typically have “user purchased item X” = positive, but no direct negative entries.  \n",
    "# We can sample some “unpurchased” items as negatives (0).  \n",
    "# \n",
    "# **Note**: For large catalogs, you might want to limit random sampling to a smaller set, or do popularity-based sampling. This code is just a simple illustration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "all_items = final_df[\"ProductID\"].unique().tolist()\n",
    "all_items_set = set(all_items)\n",
    "\n",
    "def sample_negative_items(user_item_pairs, n_neg=3):\n",
    "    \"\"\"\n",
    "    For each (user, item) in user_item_pairs, \n",
    "    returns a list of (user, item, 1) + (user, some other item, 0) with n_neg negative items.\n",
    "    \"\"\"\n",
    "    # user_item_pairs is a list/tuple of (user, item, features)\n",
    "    # We'll sample n_neg distinct item(s) that user didn't buy for each positive.\n",
    "    # Return a list of (u, i, features, y) for positives and negatives.\n",
    "    results = []\n",
    "    for (u, i, feats) in user_item_pairs:\n",
    "        # Positive\n",
    "        results.append((u, i, feats, 1.0))\n",
    "        \n",
    "        # Negative sampling\n",
    "        # randomly pick n_neg items that are NOT i\n",
    "        neg_samples = 0\n",
    "        tries = 0\n",
    "        while neg_samples < n_neg and tries < 100:  # safeguard\n",
    "            candidate = random.choice(all_items)\n",
    "            if candidate != i:\n",
    "                # Build negative features as well\n",
    "                neg_feats = feats.copy()  # you might also want to remove item-specific features, etc.\n",
    "                # We'll just keep the user-level features, but we must keep in mind the item is different\n",
    "                results.append((u, candidate, neg_feats, 0.0))\n",
    "                neg_samples += 1\n",
    "            tries += 1\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c09895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # 2. Defining a Ranking Metric: “Average Rank of Purchased Item”\n",
    "# \n",
    "# We want to measure: **“On average, at what position in the ranked list does the actually purchased item appear?”**  \n",
    "# \n",
    "# - A rank of `1` is best (the model’s top recommendation).  \n",
    "# - Larger rank means the purchased item was lower in the list.  \n",
    "# - We can keep a running average across all transactions.\n",
    "# \n",
    "# **Naïve approach** to get the rank:\n",
    "# 1. For a given transaction `(u, i)`, we compute a model score for *all candidate items* for user `u`.  \n",
    "# 2. Sort items by descending predicted score.  \n",
    "# 3. The rank is the 1-based index of the purchased item `i`.  \n",
    "# \n",
    "# **Warning**: Doing this for **every** transaction with **all** items is expensive if you have a large catalog. You might only rank a subset or use approximate methods in production.  \n",
    "# \n",
    "# For demonstration, we’ll implement a straightforward approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "class AverageRank:\n",
    "    \"\"\"\n",
    "    Online metric for average rank of the purchased item.\n",
    "    We'll track sum_of_ranks / count_of_events.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.sum_of_ranks = 0.0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, rank):\n",
    "        self.sum_of_ranks += rank\n",
    "        self.count += 1\n",
    "    \n",
    "    def get(self):\n",
    "        return self.sum_of_ranks / self.count if self.count > 0 else None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        val = self.get()\n",
    "        return f\"AverageRank={val:.3f}\" if val else \"AverageRank=None\"\n",
    "\n",
    "def get_rank(model, user_id, item_id, all_items_list, features):\n",
    "    \"\"\"\n",
    "    Scores all items for this user, returns the 1-based rank of `item_id`.\n",
    "    - `model`: River recommendation model with `predict_one(user, item, context_dict)` method.\n",
    "    - `user_id`: the ID of the user\n",
    "    - `item_id`: the ID of the purchased item\n",
    "    - `all_items_list`: list of all item IDs (caution: large if your item catalog is huge)\n",
    "    - `features`: dict of side features for the user or context\n",
    "    \"\"\"\n",
    "    # Score each item\n",
    "    scores = {}\n",
    "    for it in all_items_list:\n",
    "        # We'll augment features with \"ItemID\" so that the model can treat item as a feature\n",
    "        # or we can rely on River's \"FMRecommender\" usage: model.predict_one(user, item, context)\n",
    "        # This depends on how we define the pipeline below. We'll do a simpler version:\n",
    "        scores[it] = model.predict_one({\"user\": user_id, \"item\": it, **features})\n",
    "    \n",
    "    # Sort items by descending score\n",
    "    ranked_items = sorted(scores, key=scores.get, reverse=True)\n",
    "    \n",
    "    # Rank is index of item_id + 1\n",
    "    rank_of_purchased = ranked_items.index(item_id) + 1\n",
    "    return rank_of_purchased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74099308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # 3. Building a River “FMRecommender” Pipeline\n",
    "# \n",
    "# River has **two** main ways to do factorization-based recommendations:\n",
    "# 1. `river.reco.BiasedMF` (a simpler matrix factorization approach)\n",
    "# 2. `river.reco.FMRecommender` (Factorization Machine that can handle side features more gracefully)\n",
    "# \n",
    "# We’ll use **`FMRecommender`** below because you have many side features (demographics, brand, RFM, etc.).  \n",
    "# \n",
    "# **Key Points**:\n",
    "# - We must define how user ID, item ID, and side features are passed to the model.  \n",
    "# - `FMRecommender` expects a dictionary with keys named by default `\"user\"` and `\"item\"` (unless changed).  \n",
    "# - We can include additional features in that dictionary.  \n",
    "# - The target `y` will be `1` for positive, `0` for negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b60333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Let's define our model\n",
    "model = reco.FMRecommender(\n",
    "    n_factors=10,             # Dimensionality of the latent factors\n",
    "    intercept=True, \n",
    "    seed=42,\n",
    "    optimizer=optim=preprocessing.StandardScaler() # not typical here, \n",
    "    # but let's keep it simpler: we can just do the default Adam or SGD\n",
    "    # For example:\n",
    "    # optimizer=optim.SGD(0.01)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab50859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternatively:\n",
    "from river import optim\n",
    "model = reco.FMRecommender(\n",
    "    n_factors=10,\n",
    "    intercept=True,\n",
    "    seed=42,\n",
    "    optimizer=optim.SGD(learning_rate=0.01),  # try a small LR\n",
    "    loss=optim.loss.BPRLoss(),               # BPR pairwise ranking loss (if you want a ranking objective)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We can wrap the model with a pipeline that does feature transformations if needed, e.g., one-hot encoding\n",
    "# But FMRecommender can handle categoricals automatically if we pass them as strings.\n",
    "\n",
    "# For example:\n",
    "# pipeline = compose.Pipeline(\n",
    "#     model\n",
    "# )\n",
    "# We'll just use `model` directly in this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3aca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# # 4. Online Training Loop with Negative Sampling and Average Rank\n",
    "# \n",
    "# We’ll step through `final_df` in chronological order. For each row (transaction) we do:\n",
    "# \n",
    "# 1. Extract `(user, item, side_features, rating=1)`.  \n",
    "# 2. **Before** we update the model, we can measure the rank of the purchased item (if the user + item are not brand new).  \n",
    "#    - This simulates “the model’s knowledge up to the previous transaction.”  \n",
    "# 3. Generate negative samples for that user (0 rating).  \n",
    "# 4. Update the model with the positive and negative samples.  \n",
    "# 5. Keep track of the running average rank metric.  \n",
    "# \n",
    "# We’ll do a short loop (e.g., first 5,000 or 10,000 transactions) to keep this example from being too slow if the dataset is large.  \n",
    "# \n",
    "# **Caution**: \n",
    "# - The naive approach `get_rank` calls the model’s `predict_one` for **all items** each time. That can be extremely slow for big catalogs.  \n",
    "# - In production, consider approximations or smaller candidate sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# We create an instance of our AverageRank metric\n",
    "avg_rank_metric = AverageRank()\n",
    "\n",
    "# We define how many rows we want to process for the demo\n",
    "# You can do all rows, but it might take a very long time if the dataset is huge\n",
    "MAX_ROWS = 5000  \n",
    "\n",
    "processed = 0\n",
    "\n",
    "# We'll store some logs\n",
    "log_step = 1000\n",
    "\n",
    "for idx, row in final_df.iterrows():\n",
    "    # Limit to a subset for demonstration\n",
    "    if processed >= MAX_ROWS:\n",
    "        break\n",
    "    processed += 1\n",
    "    \n",
    "    user_id = str(row[\"ClientID\"])  # Convert to string for consistency in FM\n",
    "    item_id = str(row[\"ProductID\"])\n",
    "    \n",
    "    # Build side_features dict. You can include whichever columns are relevant.\n",
    "    # For example:\n",
    "    side_feats = {\n",
    "        \"ClientGender\": str(row[\"ClientGender\"]) if pd.notnull(row[\"ClientGender\"]) else \"Unknown\",\n",
    "        \"ClientSegment\": str(row[\"ClientSegment\"]) if pd.notnull(row[\"ClientSegment\"]) else \"Unknown\",\n",
    "        \"Brand\": str(row[\"Brand\"]) if pd.notnull(row[\"Brand\"]) else \"Unknown\",\n",
    "        \"Category\": str(row[\"Category\"]) if pd.notnull(row[\"Category\"]) else \"Unknown\",\n",
    "        \"Universe\": str(row[\"Universe\"]) if pd.notnull(row[\"Universe\"]) else \"Unknown\",\n",
    "        # Numeric features (careful to keep them numeric or string):\n",
    "        \"Age\": row[\"Age\"] if pd.notnull(row[\"Age\"]) else 0,\n",
    "        \"CumulativeSpent\": row[\"CumulativeSpent\"],\n",
    "        \"DayOfWeek\": str(row[\"DayOfWeek\"]),\n",
    "        \"Season\": str(row[\"Season\"]),\n",
    "        # etc. Add RFM or other fields if you want:\n",
    "        \"Frequency_30\": row[\"Frequency_30\"],\n",
    "        \"Recency_30\": row[\"Recency_30\"]\n",
    "        # ...\n",
    "    }\n",
    "    \n",
    "    # 1) Evaluate the rank *before* we train on this new (user, item) => \"test on the fly\"\n",
    "    #    Only do this if the model has seen some data already (i.e., after the first 100 or so)\n",
    "    if processed > 100:  # skip the very first interactions\n",
    "        rank = get_rank(model, user_id, item_id, all_items, side_feats)\n",
    "        avg_rank_metric.update(rank)\n",
    "    \n",
    "    # 2) Prepare the positive sample\n",
    "    # The model expects a dictionary with \"user\" and \"item\" keys by default\n",
    "    x_pos = {\"user\": user_id, \"item\": item_id}\n",
    "    # Also add side feats\n",
    "    x_pos.update(side_feats)\n",
    "    \n",
    "    # 3) Negative sampling for this user\n",
    "    # We'll pass them in a batch. Let's generate them:\n",
    "    # We'll do 3 negative items for demonstration\n",
    "    negative_tuples = []\n",
    "    n_neg = 3\n",
    "    negatives = set()\n",
    "    tries = 0\n",
    "    while len(negatives) < n_neg and tries < 50:\n",
    "        candidate = random.choice(all_items)\n",
    "        if candidate != item_id:\n",
    "            negatives.add(candidate)\n",
    "        tries += 1\n",
    "    \n",
    "    # 4) Update the model with the positive example\n",
    "    # BPR loss typically needs a pairwise update, but we can do an approximation:\n",
    "    model = model.learn_one(x_pos, 1.0)\n",
    "    \n",
    "    # 5) Update the model with negative examples\n",
    "    for neg_item in negatives:\n",
    "        x_neg = {\"user\": user_id, \"item\": neg_item}\n",
    "        x_neg.update(side_feats)\n",
    "        model = model.learn_one(x_neg, 0.0)\n",
    "    \n",
    "    if processed % log_step == 0:\n",
    "        print(f\"Processed {processed} transactions, current {avg_rank_metric}\")\n",
    "\n",
    "print(f\"Final Average Rank on the last {processed - 100} transactions: {avg_rank_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
