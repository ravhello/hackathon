{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7YzgxPoNnQ",
        "outputId": "b29a11a6-0959-4361-f36d-941f89e202db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/647.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-linux_x86_64.whl size=551657 sha256=c70381cb3bb9d1964e913ee49f4f1229fd77477cf50c78a7cd790ec5fd9de424\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/e5/58/0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaAXpNdNn6R6",
        "outputId": "effb03f7-31c9-4fc6-990a-3cf2dcf4b364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique products in transactions: 20638\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Item Clustering and Recommendation Script (Using KNN with Combined Features and Multi‐Product Combinations)\n",
        "-----------------------------------------------------------------------------------------------------------\n",
        "Optimized with:\n",
        "1. PCA to reduce dimensionality;\n",
        "2. Approximate Nearest Neighbors with Annoy (instead of scikit-learn NearestNeighbors);\n",
        "3. Single bulk building of the Annoy index for all items;\n",
        "4. Multi-product combos on demand or a reduced subset of products.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from itertools import combinations\n",
        "from annoy import AnnoyIndex  # pip install annoy\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Load and Prepare the Transaction Data\n",
        "# ----------------------------\n",
        "\n",
        "data_file = 'final_df.parquet'\n",
        "df = pd.read_parquet(data_file)\n",
        "\n",
        "# Convert TransactionDate to datetime if not already.\n",
        "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])\n",
        "\n",
        "# Create a BasketID by combining ClientID and TransactionDate.\n",
        "df['BasketID'] = df['ClientID'].astype(str) + '_' + df['TransactionDate'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "print(\"Number of unique products in transactions:\", df['ProductID'].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvkpsLCln6SF",
        "outputId": "acc76725-0ed7-4631-e9f4-f8864aa2a977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stocks Data Sample:\n",
            "  StoreCountry            ProductID  Quantity\n",
            "0          AUS  1284651161701379667       2.0\n",
            "1          AUS  6076274819885027797       2.0\n",
            "2          AUS  6019386668821120661       2.0\n",
            "3          AUS  2122575437123245322       2.0\n",
            "4          AUS  5901681811213086415       2.0\n",
            "\n",
            "Filtered transactions shape: (590037, 59)\n",
            "Filtered transactions sample:\n",
            "                         BasketID            ProductID  Quantity_sold\n",
            "0  4388436561084682799_2023-01-01  3260004767786243986              2\n",
            "1  5475934562856106533_2023-01-01  4081002095016762501              1\n",
            "2  7571493122530801912_2023-01-01  6392464777854173474              1\n",
            "4  7828763863563966653_2023-01-01  1064014581685647413              5\n",
            "6  8027320461473133237_2023-01-01  7562536307774112492              1\n",
            "\n",
            "Grouped data shape: (589659,)\n",
            "BasketID                        ProductID          \n",
            "1000031093718265133_2024-07-18  1789767510212328793     2\n",
            "1000031093718265133_2025-01-28  5758680089498959695     2\n",
            "1000045102759891776_2024-03-18  7259790599501851051     7\n",
            "1000045102759891776_2024-03-19  4564921709224121642     7\n",
            "1000045102759891776_2024-03-22  6157266648362222564    10\n",
            "Name: Quantity_sold, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 2. Filter Transactions by Stock Availability\n",
        "# ----------------------------\n",
        "\n",
        "stocks_data_file = 'stocks_data.csv'\n",
        "stocks_df = pd.read_csv(stocks_data_file)\n",
        "print(\"\\nStocks Data Sample:\")\n",
        "print(stocks_df.head())\n",
        "\n",
        "# Get the unique product IDs from the stocks file.\n",
        "stock_product_ids = stocks_df['ProductID'].unique()\n",
        "stock_product_ids_set = set(stock_product_ids)\n",
        "\n",
        "# Filter transactions to only include products available in stock.\n",
        "df = df[df['ProductID'].isin(stock_product_ids_set)]\n",
        "print(\"\\nFiltered transactions shape:\", df.shape)\n",
        "print(\"Filtered transactions sample:\")\n",
        "print(df[['BasketID', 'ProductID', 'Quantity_sold']].head())\n",
        "\n",
        "# (Optional) Group by basket and product to check aggregation.\n",
        "grouped = df.groupby(['BasketID', 'ProductID'])['Quantity_sold'].sum()\n",
        "print(\"\\nGrouped data shape:\", grouped.shape)\n",
        "print(grouped.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC5Lnn7Rn6SF",
        "outputId": "266e7866-4c00-49c3-f707-d28dfa3c76b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sparse basket matrix shape: (553436, 4517)\n",
            "Basket encoded shape (sparse DataFrame): (553436, 4517)\n",
            "Product features shape (from baskets): (4517, 553436)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 3. Build the Sparse Basket Matrix\n",
        "# ----------------------------\n",
        "\n",
        "# Get unique baskets and products.\n",
        "baskets = df['BasketID'].unique()\n",
        "products = df['ProductID'].unique()\n",
        "\n",
        "# Map baskets and products to indices.\n",
        "basket_to_idx = {basket: i for i, basket in enumerate(baskets)}\n",
        "product_to_idx = {product: i for i, product in enumerate(products)}\n",
        "\n",
        "row_indices = df['BasketID'].map(basket_to_idx).values\n",
        "col_indices = df['ProductID'].map(product_to_idx).values\n",
        "\n",
        "# Create binary data: 1 if purchased.\n",
        "data_values = (df['Quantity_sold'] > 0).astype(int).values\n",
        "\n",
        "# Build the sparse matrix.\n",
        "basket_sparse = csr_matrix((data_values, (row_indices, col_indices)),\n",
        "                           shape=(len(baskets), len(products)))\n",
        "print(\"\\nSparse basket matrix shape:\", basket_sparse.shape)\n",
        "\n",
        "# Convert to a pandas Sparse DataFrame.\n",
        "basket_encoded = pd.DataFrame.sparse.from_spmatrix(\n",
        "    basket_sparse,\n",
        "    index=baskets,\n",
        "    columns=products\n",
        ")\n",
        "print(\"Basket encoded shape (sparse DataFrame):\", basket_encoded.shape)\n",
        "\n",
        "# Convert columns to string just to be safe.\n",
        "basket_encoded.columns = basket_encoded.columns.astype(str)\n",
        "basket_encoded = (basket_encoded > 0).astype(int)\n",
        "\n",
        "# Transpose so that rows represent products (each row => product, each column => basket).\n",
        "product_features = basket_encoded.T\n",
        "print(\"Product features shape (from baskets):\", product_features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yav5RDHn6SG",
        "outputId": "247dc488-2e4e-4eff-eb9b-ec1d51650e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata encoded shape: (4517, 170)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 4. Load and Process Additional Product Metadata\n",
        "# ----------------------------\n",
        "\n",
        "metadata_cols = ['ProductID', 'Category', 'FamilyLevel1', 'FamilyLevel2', 'Brand']\n",
        "metadata = df[metadata_cols].drop_duplicates(subset='ProductID')\n",
        "\n",
        "metadata['ProductID'] = metadata['ProductID'].astype(str)\n",
        "metadata.set_index('ProductID', inplace=True)\n",
        "metadata = metadata.fillna('Unknown')\n",
        "\n",
        "# One-hot encode the metadata.\n",
        "metadata_encoded = pd.get_dummies(metadata)\n",
        "# Align metadata with products present in product_features.\n",
        "metadata_encoded = metadata_encoded.reindex(product_features.index).fillna(0)\n",
        "print(\"Metadata encoded shape:\", metadata_encoded.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_IIDFtAn6SG",
        "outputId": "8f6ec81d-6b09-4538-8ceb-7012552a969b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined features shape: (4517, 553606)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 5. Combine Basket-Based Features with Metadata Features\n",
        "# ----------------------------\n",
        "\n",
        "combined_features = pd.concat([product_features, metadata_encoded], axis=1)\n",
        "print(\"Combined features shape:\", combined_features.shape)\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "combined_features_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(combined_features),\n",
        "    index=combined_features.index,\n",
        "    columns=combined_features.columns\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WAsp6JJn6SG",
        "outputId": "4b8260ab-878d-4d8b-caf3-200928e9653f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after PCA reduction: (4517, 50)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 5.1 (New) Dimensionality Reduction with PCA\n",
        "# ----------------------------\n",
        "# (You can adjust n_components according to your data size/performance needs)\n",
        "n_components = 50\n",
        "pca = PCA(n_components=n_components)\n",
        "combined_reduced = pca.fit_transform(combined_features_scaled)\n",
        "\n",
        "print(f\"Shape after PCA reduction: {combined_reduced.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D98tLcrMn6SH",
        "outputId": "ea9103fb-1550-4266-d03b-e5879ddfd037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annoy index built.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 6. Build Approximate Nearest Neighbors Index (Annoy)\n",
        "# ----------------------------\n",
        "\n",
        "# Each product => an n-dimensional vector in \"combined_reduced\".\n",
        "# We'll build an Annoy index of dimension = n_components\n",
        "annoy_index = AnnoyIndex(n_components, metric='angular')\n",
        "# 'angular' effectively approximates cosine distance in Annoy\n",
        "\n",
        "product_index_list = combined_features_scaled.index.tolist()  # ProductIDs\n",
        "productID_to_annoyIndex = {}\n",
        "annoyIndex_to_productID = {}\n",
        "\n",
        "# Add items to the Annoy index\n",
        "for i, pid in enumerate(product_index_list):\n",
        "    vector = combined_reduced[i]\n",
        "    annoy_index.add_item(i, vector.tolist())\n",
        "    productID_to_annoyIndex[pid] = i\n",
        "    annoyIndex_to_productID[i] = pid\n",
        "\n",
        "# Build the index. \"n_trees\" ~ 10..50 can be tuned for speed/accuracy tradeoff\n",
        "annoy_index.build(n_trees=10)\n",
        "print(\"Annoy index built.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eOYppjDBn6SH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 7. Recommendation Function (Single & Multi-Product) using Annoy\n",
        "# ----------------------------\n",
        "\n",
        "def recommend_for_single_product(pid, annoy_idx, top_n=5):\n",
        "    \"\"\"\n",
        "    Return top_n nearest neighbor product IDs for a single product pid.\n",
        "    Excludes pid itself.\n",
        "    \"\"\"\n",
        "    if pid not in productID_to_annoyIndex:\n",
        "        return []\n",
        "    idx = productID_to_annoyIndex[pid]\n",
        "    # Get nns from Annoy\n",
        "    neighbor_indices = annoy_idx.get_nns_by_item(idx, top_n+1, include_distances=False)\n",
        "    # The first one might be the item itself\n",
        "    recommendations = []\n",
        "    for ni in neighbor_indices:\n",
        "        if ni != idx:\n",
        "            recommendations.append(annoyIndex_to_productID[ni])\n",
        "        if len(recommendations) >= top_n:\n",
        "            break\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "def recommend_for_combinations(basket_products, annoy_idx, top_n=5, combination_sizes=[1, 2, 3]):\n",
        "    \"\"\"\n",
        "    For a given set of products (basket_products), compute approximate recommendations\n",
        "    for every combination (of sizes in combination_sizes) by averaging the PCA vectors and querying Annoy.\n",
        "\n",
        "    NOTE: Doing this for large sets is expensive. Typically do it on-demand (e.g. for a user’s actual cart).\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    # Gather valid products\n",
        "    valid_products = [p for p in basket_products if p in productID_to_annoyIndex]\n",
        "\n",
        "    for r in combination_sizes:\n",
        "        for combo in combinations(valid_products, r):\n",
        "            # Average the reduced vectors\n",
        "            vectors = []\n",
        "            for pid in combo:\n",
        "                i = productID_to_annoyIndex[pid]\n",
        "                vectors.append(combined_reduced[i])\n",
        "            mean_vec = np.mean(vectors, axis=0)\n",
        "\n",
        "            # Query Annoy using the vector\n",
        "            neighbor_indices = annoy_idx.get_nns_by_vector(mean_vec.tolist(), top_n+len(combo))\n",
        "\n",
        "            # Filter out the products in combo\n",
        "            neighbor_ids = []\n",
        "            for ni in neighbor_indices:\n",
        "                candidate_pid = annoyIndex_to_productID[ni]\n",
        "                if candidate_pid not in combo:\n",
        "                    neighbor_ids.append(candidate_pid)\n",
        "                if len(neighbor_ids) >= top_n:\n",
        "                    break\n",
        "            results[combo] = neighbor_ids\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combos_to_serializable(combos_dict):\n",
        "    \"\"\"\n",
        "    Convert combos_dict from:\n",
        "       {('A',): [rec1, rec2, ...], ('B','C'): [rec1, rec2, ...], ...}\n",
        "    to a list of dicts with string keys:\n",
        "       [\n",
        "         {'combo': \"A\", 'recommendations': [rec1, rec2, ...]},\n",
        "         {'combo': \"B,C\", 'recommendations': [...]},\n",
        "         ...\n",
        "       ]\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for combo_tuple, recs in combos_dict.items():\n",
        "        combo_str = \",\".join(combo_tuple)\n",
        "        output.append({'combo': combo_str, 'recommendations': recs})\n",
        "    return output"
      ],
      "metadata": {
        "id": "4tjveEtwrEMx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9EM8qJsn6SH",
        "outputId": "f94e1a3e-0396-4c5a-f9f3-6f16da63647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Single-product recommendations saved to product_recommendations_single_ANN_with_PCA.parquet\n",
            "\n",
            "Multi-product combo recommendations for ALL products saved to multi_product_combo_recommendations_ANN_with_PCA.parquet\n",
            "\n",
            "Recommendation generation complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 8. Generate and Save Recommendations\n",
        "# ----------------------------\n",
        "if __name__ == '__main__':\n",
        "    # -----------------------------------------------------------------\n",
        "    # A) Single-product recommendations for ALL products (fast approach)\n",
        "    # -----------------------------------------------------------------\n",
        "    recommendations_list = []\n",
        "    for pid in product_index_list:\n",
        "        recs = recommend_for_single_product(pid, annoy_index, top_n=5)\n",
        "        recommendations_list.append({\n",
        "            'ProductID': pid,\n",
        "            'SingleProduct_Recommendations': recs\n",
        "        })\n",
        "\n",
        "    single_df = pd.DataFrame(recommendations_list)\n",
        "    single_df.to_parquet('product_recommendations_single_ANN_with_PCA.parquet', index=False)\n",
        "    print(\"\\nSingle-product recommendations saved to product_recommendations_single_ANN_with_PCA.parquet\")\n",
        "\n",
        "    # B) Multi-product combos for ALL products\n",
        "    # WARNING: Enumerating multi-product combinations can be computationally expensive.\n",
        "    # Here, for each product, we call recommend_for_combinations with a single-item basket,\n",
        "    # which for combination sizes 2 and 3 will be empty, so effectively it's similar to single-product.\n",
        "    # In a real-world scenario, multi-product combos are usually computed on-demand (e.g. for a user's cart).\n",
        "\n",
        "    combos_recommendations = []\n",
        "    for pid in product_index_list:\n",
        "        combo_recs = recommend_for_combinations([pid], annoy_index, top_n=5, combination_sizes=[1,2,3,4,5])\n",
        "        serialized = combos_to_serializable(combo_recs)\n",
        "        combos_recommendations.append({\n",
        "            'ProductID': pid,\n",
        "            'Combination_Recommendations': serialized\n",
        "        })\n",
        "\n",
        "    combos_df = pd.DataFrame(combos_recommendations)\n",
        "    combos_df.to_parquet('multi_product_combo_recommendations_ANN_with_PCA.parquet', index=False)\n",
        "    print(\"\\nMulti-product combo recommendations for ALL products saved to multi_product_combo_recommendations_ANN_with_PCA.parquet\")\n",
        "\n",
        "    print(\"\\nRecommendation generation complete.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}